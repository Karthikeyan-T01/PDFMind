This project is a Document Question Answering (DocQA) application built with Streamlit, LangChain, FAISS, and Groqâ€™s LLaMA-4 model. It allows users to upload PDF documents, which are automatically processed, split, and converted into semantic embeddings using Hugging Face models. These embeddings are stored in a FAISS vector store to enable fast and accurate similarity search.

When a user asks a question, the app retrieves the most relevant chunks from the PDFs and passes them to Groqâ€™s LLaMA-4 model via LangChain to generate context-aware answers â€” all through an easy-to-use web interface.

Itâ€™s ideal for:

ğŸ“š Students who want to ask questions about their course notes

ğŸ§  Researchers who need fast answers from large documents

ğŸ“„ Anyone working with unstructured PDFs and looking to extract knowledge easily

ğŸŒ You can get the API from " Groqâ€™s ultra-fast API and LLaMA-4 models "
